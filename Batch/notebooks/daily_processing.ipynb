{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788f3a40-58cf-4d32-8fdd-08a8fb7b6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format, dayofmonth, month, year, quarter, substring_index, split, when, concat_ws, lit,round\n",
    "from pyspark.sql.types import DateType\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b50ba9-491f-4e94-869c-b5eac7721817",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .appName(\"daily_processing\")\\\n",
    "    .config(\"spark.eventLog.logBlockUpdates.enabled\", True)\\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659aa54e-aee8-4e0a-b760-36d8e3fe4f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Year: 2023, Month: 07, Day: 03\n"
     ]
    }
   ],
   "source": [
    "# Get the current time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Subtract one year and one day\n",
    "new_time = current_time - timedelta(days=367)\n",
    "\n",
    "# Format the previous hour's directory path\n",
    "year = new_time.strftime(\"%Y\")\n",
    "month = new_time.strftime(\"%m\")\n",
    "day = new_time.strftime(\"%d\")\n",
    "print(f\" Year: {year}, Month: {month}, Day: {day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fea89b6-9485-44ce-817d-fb2b7a9e46f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>sales_agent_name</th><th>product_name</th><th>total_units_sold</th></tr>\n",
       "<tr><td>David Wilson</td><td>Boots</td><td>9</td></tr>\n",
       "<tr><td>Michael Johnson</td><td>Printer</td><td>2</td></tr>\n",
       "<tr><td>Olivia Davis</td><td>Printer</td><td>1</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+------------+----------------+\n",
       "|sales_agent_name|product_name|total_units_sold|\n",
       "+----------------+------------+----------------+\n",
       "|    David Wilson|       Boots|               9|\n",
       "| Michael Johnson|     Printer|               2|\n",
       "|    Olivia Davis|     Printer|               1|\n",
       "+----------------+------------+----------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get sales agents performance\n",
    "\n",
    "sql_query = f\"\"\"\n",
    "SELECT\n",
    "    s.name AS sales_agent_name,\n",
    "    p.product_name,\n",
    "    SUM(sf.units) AS total_units_sold\n",
    "FROM\n",
    "    retail.sales_transactions_Fact sf\n",
    "JOIN\n",
    "    retail.product_dim p ON sf.product_id = p.product_id\n",
    "JOIN\n",
    "    retail.sales_agents_Dim s ON s.sales_person_id = sf.sales_agent_id\n",
    "WHERE\n",
    "    sf.day = '{day}' AND sf.year = '{year}' AND sf.month = '{month}'\n",
    "GROUP BY\n",
    "    s.name, p.product_name\n",
    "ORDER BY\n",
    "    total_units_sold DESC\n",
    "\"\"\"\n",
    "sales_agents_performance = spark.sql(sql_query)\n",
    "\n",
    "sales_agents_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6671b644-bc51-40d7-b580-72decd7c0a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to file:///data/project/daily_reports/25-05-2023/\n"
     ]
    }
   ],
   "source": [
    "# Define the output path where you want to save the CSV file\n",
    "output_path = f\"file:///data/project/daily_reports/{day}-{month}-{year}/\"\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "most_selling_product.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path)\n",
    "# Print confirmation\n",
    "print(f\"DataFrame saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30582416-55aa-47ac-b830-8fe2badea98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
